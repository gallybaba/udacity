{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Sample Project\n",
    "## Data Wrangling with MongoDB\n",
    "### Karun Gahlawat\n",
    "#### Dallas\n",
    "#### https://s3.amazonaws.com/metro-extracts.mapzen.com/dallas_texas.osm.bz2\n",
    "### http://www.openstreetmap.org/#map=10/32.7740/-96.7902\n",
    "\n",
    "\n",
    "**DALLAS AREA EXPLORATION SECTION STARTS FINAL PROJECT CODE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered In Map\n",
    "\n",
    "### Data Size\n",
    "The area picked is +500MB and is very slow to process basically anything on it. This dataset cannot be loaded / pushed into github and it took a lot of time to push it into mongodb. Especially, if inserting one by one. The idea behind inserting one by one was to take that opportunity to clean it as we go and then insert it. It appears though cleaning this data before inserting or after inserting is a\n",
    "better way.\n",
    "\n",
    "### Street Types Over Complicated for simple regular expressions\n",
    "The street types in general are easily correctable. For e.g Road is types as Road and even if it is typed as Rd., it is a common replace string. Having said that (output.txt), 161 records out of 5558972 records have little ways to correct them.\n",
    "\n",
    "In some cases, we have street names like __5229 alpha road dallas tx 75240 __. This would cause the regular expression to take street type as __75240__ due to the assumption that last street names would only include street names and not the whole address. In some other cases, __3740 N. Josey Lane, Suite 121 __ would appear. In this case __121__ would appear as street type.\n",
    "\n",
    "The solution to this would be to iterate through these records again and again bring them into a simpler form. This would require some manual input.\n",
    "\n",
    "### Postcodes are not really postcodes\n",
    "**__<tag k=\"addr:postcode\" v=\"TX\"/>__** this isn't really a postal code but a state. there is no simple soution to this it would seem. One way to fix it woud be to gather as much data as we can about address and cross reference it with google or like and get the right zipcode. That is a non trivial task.\n",
    "\n",
    "### Extra fields in some but not most records\n",
    "Some extra fields are found in some records like \n",
    "   * __tag k=\"building\" v=\"office\"/__\n",
    "   * __tag k=\"building:levels\" v=\"2\"/__\n",
    "   * __tag k=\"sport\" v=\"swimming\"/__\n",
    "   * __tag k=\"amenity\" v=\"parking\"/__\n",
    "   \n",
    "these tags are not very common and would require to change the db schema a little bit to accomodate them. They seem like a nice addition to the __way__ node that further describes some extra information about the way.\n",
    "\n",
    "## Overview of Data\n",
    "*_Please see Last Section for Code Details that produced this data_*\n",
    "\n",
    "   * Total Records In DB:  5558972\n",
    "   * Data Size In DB:  1.3GB\n",
    "   * First Record In DB:  {u'id': u'26450261', u'_id': ObjectId('56f1d4af222cc489da99b3f0'), u'type': u'node', u'pos': [-97.0027785, 32.9901295], u'created': {u'changeset': u'641383', u'version': u'4', u'user': u'brianboru', u'timestamp': u'2008-10-31T13:10:04Z', u'uid': u'9065'}}\n",
    "   * Top 5 Users\n",
    "      * User  5 {u'count': 2254674, u'_id': u'woodpeck_fixbot'}\n",
    "      * User  4 {u'count': 198416, u'_id': u'fmmute'}\n",
    "      * User  3 {u'count': 176820, u'_id': u'TexasNHD'}\n",
    "      * User  2 {u'count': 123490, u'_id': u'25or6to4'}\n",
    "      * User  1 {u'count': 121506, u'_id': u'Chris Lawrence'}\n",
    "   * Top 5 Zip Codes\n",
    "      * Zip Code  5 {u'count': 1211, u'_id': u'75104'}\n",
    "      * Zip Code  4 {u'count': 629, u'_id': u'75093'}\n",
    "      * Zip Code  3 {u'count': 343, u'_id': u'75070'}\n",
    "      * Zip Code  2 {u'count': 227, u'_id': u'75051'}\n",
    "      * Zip Code  1 {u'count': 181, u'_id': u'75069'}\n",
    "      * address records:  119075\n",
    "   * Size of xml downloaded : + 500MB\n",
    "   * Size of json created: +250MB\n",
    "\n",
    "## Additional Ideas\n",
    "\n",
    "   * Needs more input for completeness. Fields like amenities, levels and others are important part of location information that could substantially increase the quality of this data.\n",
    "   * Most of the data input is by top 5 users. This data is relatively clean. For e.g. only 161 street types out of 5.5 Million records are un retrievable.\n",
    "   * Given more iterations, this data could be further processed and mapped to its quality.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "   * This is a *great* effort by Texans. With a little bit of information and processing, this massive data set could become a LOT useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 6 Problems Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 3,\n",
      " 'nd': 4,\n",
      " 'node': 20,\n",
      " 'osm': 1,\n",
      " 'relation': 1,\n",
      " 'tag': 7,\n",
      " 'way': 1}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Your task is to use the iterative parsing to process the map file and\n",
    "find out not only what tags are there, but also how many, to get the\n",
    "feeling on how much of which data you can expect to have in the map.\n",
    "Fill out the count_tags function. It should return a dictionary with the \n",
    "tag name as the key and number of times this tag can be encountered in \n",
    "the map as value.\n",
    "\n",
    "Note that your code will be tested with a different data file than the 'example.osm'\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "        # YOUR CODE HERE\n",
    "    tags = {}\n",
    "    context = ET.iterparse(filename, events=('start', 'end'))\n",
    "    context = iter(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'start':\n",
    "            if elem.tag in tags:\n",
    "                tags[elem.tag] += 1\n",
    "            else:\n",
    "                tags[elem.tag] = 1\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('example.osm')\n",
    "    pprint.pprint(tags)\n",
    "    assert tags == {'bounds': 1,\n",
    "                     'member': 3,\n",
    "                     'nd': 4,\n",
    "                     'node': 20,\n",
    "                     'osm': 1,\n",
    "                     'relation': 1,\n",
    "                     'tag': 7,\n",
    "                     'way': 1}\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example File for Lesson 6 Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<osm version=\"0.6\" generator=\"CGImap 0.3.3 (28791 thorn-03.openstreetmap.org)\" copyright=\"OpenStreetMap and contributors\" attribution=\"http://www.openstreetmap.org/copyright\" license=\"http://opendatacommons.org/licenses/odbl/1-0/\">\n",
    " <bounds minlat=\"41.9704500\" minlon=\"-87.6928300\" maxlat=\"41.9758200\" maxlon=\"-87.6894800\"/>\n",
    " <node id=\"261114295\" visible=\"true\" version=\"7\" changeset=\"11129782\" timestamp=\"2012-03-28T18:31:23Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9730791\" lon=\"-87.6866303\"/>\n",
    " <node id=\"261114296\" visible=\"true\" version=\"6\" changeset=\"8448766\" timestamp=\"2011-06-15T17:04:54Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9730416\" lon=\"-87.6878512\"/>\n",
    " <node id=\"261114299\" visible=\"true\" version=\"5\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:14Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9729565\" lon=\"-87.6939548\"/>\n",
    " <node id=\"261146436\" visible=\"true\" version=\"5\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:14Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9707380\" lon=\"-87.6976025\"/>\n",
    " <node id=\"261147304\" visible=\"true\" version=\"7\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:15Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9740068\" lon=\"-87.6988576\"/>\n",
    " <node id=\"261224274\" visible=\"true\" version=\"5\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:14Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9707656\" lon=\"-87.6938669\"/>\n",
    " <node id=\"293816175\" visible=\"true\" version=\"47\" changeset=\"8448766\" timestamp=\"2011-06-15T16:55:37Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9730154\" lon=\"-87.6890403\"/>\n",
    " <node id=\"305896090\" visible=\"true\" version=\"37\" changeset=\"15348240\" timestamp=\"2013-03-13T07:46:29Z\" user=\"Umbugbene\" uid=\"567034\" lat=\"41.9749225\" lon=\"-87.6891198\"/>\n",
    " <node id=\"317636974\" visible=\"true\" version=\"12\" changeset=\"15348240\" timestamp=\"2013-03-13T08:02:56Z\" user=\"Umbugbene\" uid=\"567034\" lat=\"41.9740292\" lon=\"-87.7012430\"/>\n",
    " <node id=\"317636971\" visible=\"true\" version=\"13\" changeset=\"15348240\" timestamp=\"2013-03-13T08:08:01Z\" user=\"Umbugbene\" uid=\"567034\" lat=\"41.9740556\" lon=\"-87.6979712\"/>\n",
    " <node id=\"317637399\" visible=\"true\" version=\"2\" changeset=\"14927972\" timestamp=\"2013-02-05T22:43:49Z\" user=\"Umbugbene\" uid=\"567034\" lat=\"41.9705609\" lon=\"-87.7012048\"/>\n",
    " <node id=\"317637398\" visible=\"true\" version=\"2\" changeset=\"14927972\" timestamp=\"2013-02-05T22:43:49Z\" user=\"Umbugbene\" uid=\"567034\" lat=\"41.9706972\" lon=\"-87.7012109\"/>\n",
    " <node id=\"365214872\" visible=\"true\" version=\"3\" changeset=\"8448766\" timestamp=\"2011-06-15T17:04:54Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9731130\" lon=\"-87.6847998\"/>\n",
    " <node id=\"261299091\" visible=\"true\" version=\"6\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:15Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9747482\" lon=\"-87.6988886\"/>\n",
    " <node id=\"261114294\" visible=\"true\" version=\"6\" changeset=\"8448766\" timestamp=\"2011-06-15T17:04:54Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9731219\" lon=\"-87.6841979\"/>\n",
    " <node id=\"261210804\" visible=\"true\" version=\"4\" changeset=\"3359748\" timestamp=\"2009-12-13T00:36:09Z\" user=\"woodpeck_fixbot\" uid=\"147510\" lat=\"41.9707217\" lon=\"-87.7000019\"/>\n",
    " <node id=\"261221422\" visible=\"true\" version=\"7\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:15Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9748542\" lon=\"-87.6922652\"/>\n",
    " <node id=\"261221424\" visible=\"true\" version=\"7\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:15Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9758794\" lon=\"-87.6923639\">\n",
    "  <tag k=\"highway\" v=\"traffic_signals\"/>\n",
    " </node>\n",
    " <node id=\"261198953\" visible=\"true\" version=\"6\" changeset=\"8581395\" timestamp=\"2011-06-29T14:14:13Z\" user=\"bbmiller\" uid=\"451048\" lat=\"41.9707413\" lon=\"-87.6963097\"/>\n",
    " <node id=\"757860928\" visible=\"true\" version=\"2\" changeset=\"5288876\" timestamp=\"2010-07-22T16:16:51Z\" user=\"uboot\" uid=\"26299\" lat=\"41.9747374\" lon=\"-87.6920102\">\n",
    "  <tag k=\"amenity\" v=\"fast_food\"/>\n",
    "  <tag k=\"cuisine\" v=\"sausage\"/>\n",
    "  <tag k=\"name\" v=\"Shelly's Tasty Freeze\"/>\n",
    " </node>\n",
    "  <way id=\"258219703\" visible=\"true\" version=\"1\" changeset=\"20187382\" timestamp=\"2014-01-25T02:01:54Z\" user=\"linuxUser16\" uid=\"1219059\">\n",
    "  <nd ref=\"2636086179\"/>\n",
    "  <nd ref=\"2636086178\"/>\n",
    "  <nd ref=\"2636086177\"/>\n",
    "  <nd ref=\"2636086176\"/>\n",
    "  <tag k=\"highway\" v=\"service\"/>\n",
    " </way>\n",
    " <relation id=\"1557627\" visible=\"true\" version=\"2\" changeset=\"14326854\" timestamp=\"2012-12-19T05:32:37Z\" user=\"fredr\" uid=\"939355\">\n",
    "  <member type=\"node\" ref=\"1258927212\" role=\"via\"/>\n",
    "  <member type=\"way\" ref=\"110160127\" role=\"from\"/>\n",
    "  <member type=\"way\" ref=\"34073105\" role=\"to\"/>\n",
    "  <tag k=\"restriction\" v=\"only_right_turn\"/>\n",
    "  <tag k=\"type\" v=\"restriction\"/>\n",
    " </relation>\n",
    "</osm>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway\n",
      "\tlower\n",
      "amenity\n",
      "\tlower\n",
      "cuisine\n",
      "\tlower\n",
      "name\n",
      "\tlower\n",
      "highway\n",
      "\tlower\n",
      "restriction\n",
      "\tlower\n",
      "type\n",
      "\tlower\n",
      "{'lower': 7, 'lower_colon': 0, 'other': 0, 'problemchars': 0}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4789581f47a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-4789581f47a6>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'example.osm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lower_colon'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'other'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'problemchars'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into MongoDB, you should check the \"k\"\n",
    "value for each \"<tag>\" and see if they can be valid keys in MongoDB, as well as\n",
    "see if there are any other potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data\n",
    "model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of\n",
    "four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "See the 'process_map' and 'test' functions for examples of the expected format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # YOUR CODE HERE\n",
    "        kvalue = element.attrib['k']\n",
    "        print kvalue\n",
    "        if lower.match(kvalue):\n",
    "            print '\\tlower'\n",
    "            if 'lower' in keys:\n",
    "                keys['lower'] += 1\n",
    "            else:\n",
    "                keys['lower'] = 1\n",
    "        elif lower_colon.match(kvalue):\n",
    "            print '\\tlower_colon'\n",
    "            if 'lower_colon' in keys:\n",
    "                keys['lower_colon'] += 1\n",
    "            else:\n",
    "                keys['lower_colon'] = 1\n",
    "        elif problemchars.match(kvalue):\n",
    "            print '\\tproblemchars'\n",
    "            if 'problemchars' in keys:\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['problemchars'] = 1\n",
    "        else:\n",
    "            print '\\tothers'\n",
    "            if 'other' in keys:        \n",
    "                keys['other'] += 1\n",
    "            else:\n",
    "                keys['other'] = 1\n",
    "    \n",
    "    #print keys\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    keys = process_map('example.osm')\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 5, 'lower_colon': 0, 'other': 2, 'problemchars': 0}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Umbugbene',\n",
      "     'bbmiller',\n",
      "     'fredr',\n",
      "     'linuxUser16',\n",
      "     'uboot',\n",
      "     'woodpeck_fixbot'])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if 'user' in element.attrib:\n",
    "            users.add(element.attrib['user'])\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map('example.osm')\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 6\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit and Fix Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-930afafd8298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-930afafd8298>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mst_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOSMFILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"example.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"N.\": \"North\",\n",
    "            \"Ave\": \"Avenue\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #print \"name:=\" , name\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        st = m.group()\n",
    "        if st not in expected:\n",
    "            name = re.sub(st, mapping[st], name)\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for MongoDB using JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'address'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f5a6c54c972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-6f5a6c54c972>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;31m#print \"expected      : \", correct_first_elem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcorrect_first_elem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     assert data[-1][\"address\"] == {\n\u001b[0m\u001b[0;32m    249\u001b[0m                                     \u001b[1;34m\"street\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"West Lexington St.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                                     \u001b[1;34m\"housenumber\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"1412\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'address'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\"\"\"\n",
    "Your task is to wrangle the data and transform the shape of the data\n",
    "into the model we mentioned earlier. The output should be a list of dictionaries\n",
    "that look like this:\n",
    "\n",
    "{\n",
    "\"id\": \"2406124091\",\n",
    "\"type: \"node\",\n",
    "\"visible\":\"true\",\n",
    "\"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "\"pos\": [41.9757030, -87.6921867],\n",
    "\"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "\"amenity\": \"restaurant\",\n",
    "\"cuisine\": \"mexican\",\n",
    "\"name\": \"La Cabana De Don Luis\",\n",
    "\"phone\": \"1 (773)-271-5176\"\n",
    "}\n",
    "\n",
    "You have to complete the function 'shape_element'.\n",
    "We have provided a function that will parse the map file, and call the function with the element\n",
    "as an argument. You should return a dictionary, containing the shaped data for that element.\n",
    "We have also provided a way to save the data in a file, so that you could use\n",
    "mongoimport later on to import the shaped data into MongoDB. \n",
    "\n",
    "Note that in this exercise we do not use the 'update street name' procedures\n",
    "you worked on in the previous exercise. If you are using this code in your final\n",
    "project, you are strongly encouraged to use the code from previous exercise to \n",
    "update the street names before you save them to JSON. \n",
    "\n",
    "In particular the following things should be done:\n",
    "- you should process only 2 types of top level tags: \"node\" and \"way\"\n",
    "- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "    - attributes in the CREATED array should be added under a key \"created\"\n",
    "    - attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings. \n",
    "- if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "- if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "- if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n",
    "  process it in a way that you feel is best. For example, you might split it into a two-level\n",
    "  dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.\n",
    "- if there is a second \":\" that separates the type/direction of a street,\n",
    "  the tag should be ignored, for example:\n",
    "\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "\n",
    "  should be turned into:\n",
    "\n",
    "{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}\n",
    "\n",
    "- for \"way\" specifically:\n",
    "\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "\n",
    "should be turned into\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        # YOUR CODE HERE\n",
    "        if element.tag == \"node\":\n",
    "            node['type'] = 'node'\n",
    "        elif element.tag == \"way\":\n",
    "            node['type'] = 'way'\n",
    "        #\"id\": \"2406124091\",\n",
    "#\"type: \"node\",\n",
    "#\"visible\":\"true\",\n",
    "#\"created\": {\n",
    "#          \"version\":\"2\",\n",
    "#          \"changeset\":\"17206049\",\n",
    "#          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "#          \"user\":\"linuxUser16\",\n",
    "#          \"uid\":\"1219059\"\n",
    "#        },\n",
    "#\"pos\": [41.9757030, -87.6921867],\n",
    "#\"address\": {\n",
    "#          \"housenumber\": \"5157\",\n",
    "#          \"postcode\": \"60625\",\n",
    "#          \"street\": \"North Lincoln Ave\"\n",
    "#        },\n",
    "#\"amenity\": \"restaurant\",\n",
    "#\"cuisine\": \"mexican\",\n",
    "#\"name\": \"La Cabana De Don Luis\",\n",
    "#\"phone\": \"1 (773)-271-5176\"\n",
    "#}\n",
    "        atts = element.attrib\n",
    "        address = {}\n",
    "        pos = []\n",
    "        created = {}\n",
    "        node_refs = []\n",
    "        node['address'] = address\n",
    "        node['pos'] = pos\n",
    "        node['created'] = created\n",
    "        node['node_refs'] = node_refs\n",
    "        ### parent level attributes\n",
    "        for k,v in atts.iteritems():\n",
    "            if k == 'id':\n",
    "                node[k] = v\n",
    "            elif k == 'visible':\n",
    "                node[k] = v\n",
    "            elif k == 'amenity':\n",
    "                node[k] = v\n",
    "            elif k == 'name':\n",
    "                node[k] = v\n",
    "            elif k == 'phone':\n",
    "                node[k] = v\n",
    "            elif k == 'version':\n",
    "                created[k] = v\n",
    "            elif k == 'changeset':\n",
    "                created[k] = v\n",
    "            elif k == 'timestamp':\n",
    "                created[k] = v\n",
    "            elif k == 'user':\n",
    "                created[k] = v\n",
    "            elif k == 'uid':\n",
    "                created[k] = v\n",
    "            elif k == 'lon':\n",
    "                pos.append(float(v))\n",
    "            elif k == 'lat':\n",
    "                pos.append(float(v))\n",
    "                \n",
    "        #### child nodes\n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                node_refs.append(child.attrib['ref'])\n",
    "            elif child.tag == 'tag':\n",
    "                ktag = child.attrib['k']\n",
    "                vtag = child.attrib['v']\n",
    "                if not problemchars.match(vtag):\n",
    "                    if ktag == \"addr:city\":\n",
    "                        address['city'] = vtag\n",
    "                    elif ktag == \"addr:housenumber\":\n",
    "                        address['housenumber'] = vtag\n",
    "                    elif ktag == \"addr:postcode\":\n",
    "                        address['postcode'] = vtag\n",
    "                    elif ktag == \"addr:street\":\n",
    "                        address['street'] = vtag\n",
    "                    elif ktag == 'amenity':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'cuisine':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'name':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'phone':\n",
    "                        node[ktag] = vtag\n",
    "                        \n",
    "  ##<tag k=\"addr:city\" v=\"Chicago\"/>\n",
    "  ##<tag k=\"addr:housenumber\" v=\"5157\"/>\n",
    "  ##<tag k=\"addr:postcode\" v=\"60625\"/>\n",
    "  ##<tag k=\"addr:street\" v=\"North Lincoln Ave\"/>\n",
    "  ##<tag k=\"amenity\" v=\"restaurant\"/>\n",
    "  ##<tag k=\"cuisine\" v=\"mexican\"/>\n",
    "  ##<tag k=\"name\" v=\"La Cabana De Don Luis\"/>\n",
    "  ##<tag k=\"outdoor_seating\" v=\"no\"/>\n",
    "  ##<tag k=\"phone\" v=\"1 (773)-271-5176\"/>\n",
    "  ##<tag k=\"smoking\" v=\"no\"/>\n",
    "  ##<tag k=\"takeaway\" v=\"yes\"/>             \n",
    "        if len(address) == 0:\n",
    "            del node['address']\n",
    "        if len(node_refs) == 0:\n",
    "            del node['node_refs']\n",
    "        if len(pos) == 0:\n",
    "            del node['pos']        \n",
    "        #print \"returning node: \", node\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "def test():\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map('example.osm', True)\n",
    "    #pprint.pprint(data)\n",
    "    \n",
    "    correct_first_elem = {\n",
    "        \"id\": \"261114295\", \n",
    "        \"visible\": \"true\", \n",
    "        \"type\": \"node\", \n",
    "        \"pos\": [-87.6866303, 41.9730791], \n",
    "        \"created\": {\n",
    "            \"changeset\": \"11129782\", \n",
    "            \"user\": \"bbmiller\", \n",
    "            \"version\": \"7\", \n",
    "            \"uid\": \"451048\", \n",
    "            \"timestamp\": \"2012-03-28T18:31:23Z\"\n",
    "        }\n",
    "    }\n",
    "    #print \"actual data[0]: \", data[0]\n",
    "    #print \"expected      : \", correct_first_elem\n",
    "    assert data[0] == correct_first_elem\n",
    "    assert data[-1][\"address\"] == {\n",
    "                                    \"street\": \"West Lexington St.\", \n",
    "                                    \"housenumber\": \"1412\"\n",
    "                                      }\n",
    "    assert data[-1][\"node_refs\"] == [ \"2199822281\", \"2199822390\",  \"2199822392\", \"2199822369\", \n",
    "                                    \"2199822370\", \"2199822284\", \"2199822281\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dallas Area Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "######################\n",
    "### over all comments ###\n",
    "'''\n",
    "file structure is divided into three categories\n",
    "1) globals and utility functions like mapping, audit_street and shape_elements\n",
    "these functions provide reference data and some utility based functionality\n",
    "2) process map: this function iterates over xml file and creates appropriate \n",
    "structures and returns them. idea is to iterate over this file once and gather \n",
    "any / all information that we can in one shot. it is a HUGE data set.\n",
    "3) insert_mongo: which creates data one by one into mongo db instance. this step\n",
    "is bypassed for ease of testing and relplaced by \n",
    "---------------------------------------------------------------------------------\n",
    "mongoimport --db udacity --collection dallas --file dallas_texas.osm.json  --drop\n",
    "---------------------------------------------------------------------------------\n",
    "over all idea is to follow lesson 6 problem sets and twist and turn for this data set.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "'''\n",
    "global regular expressions for determining \n",
    "category of data\n",
    "'''\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "#### global street type categorizer\n",
    "#### \\bSt\\. will pick up Street\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "##### expected street types\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Highway\"]\n",
    "\n",
    "# mapping of incorrect street types to correct ones\n",
    "# use this dict to replace incorrect street types\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"N.\": \"North\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Tr\" : \"Trail\",\n",
    "            \"Tr.\": \"Trail\",\n",
    "            \"Trl\": \"Trail\",\n",
    "            \"S.\" : \"South\",\n",
    "            \"W.\" : \"West\",\n",
    "            \"W\" : \"West\",\n",
    "            \"S\" : \"South\",\n",
    "            \"W\" : \"West\",\n",
    "            \"Pkwy\" : \"Parkway\",\n",
    "            \"Hwy\" : \"Highway\",\n",
    "            \"E\" : \"East\",\n",
    "            \"E.\" : \"East\",\n",
    "            \"Blvd\" : \"Boulevard\",\n",
    "            \"Blvd.\" : \"Boulevard\"\n",
    "           \n",
    "            }\n",
    "\n",
    "#### all the street types that are left out by the \n",
    "### street_type_re expression are into this.\n",
    "#### this needs a second look\n",
    "\n",
    "incomplete_mapping = set()\n",
    "\n",
    "'''\n",
    "categorizes tags into lower, lower with a colon and problem chars\n",
    "'''\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        kvalue = element.attrib['k']\n",
    "        #print kvalue\n",
    "        if lower.match(kvalue):\n",
    "            #print '\\tlower'\n",
    "            if 'lower' in keys:\n",
    "                keys['lower'] += 1\n",
    "            else:\n",
    "                keys['lower'] = 1\n",
    "        elif lower_colon.match(kvalue):\n",
    "            #print '\\tlower_colon'\n",
    "            if 'lower_colon' in keys:\n",
    "                keys['lower_colon'] += 1\n",
    "            else:\n",
    "                keys['lower_colon'] = 1\n",
    "        elif problemchars.match(kvalue):\n",
    "            #print '\\tproblemchars'\n",
    "            if 'problemchars' in keys:\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['problemchars'] = 1\n",
    "        else:\n",
    "            #print '\\tothers'\n",
    "            if 'other' in keys:        \n",
    "                keys['other'] += 1\n",
    "            else:\n",
    "                keys['other'] = 1\n",
    "    \n",
    "    #print keys\n",
    "    return keys\n",
    "\n",
    "#### runs over al street types and assess them as expected or un expected\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            #print \"adding street type to unexpected: \", street_type, street_name\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "#### if element attribute is a street addresss\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#### update unexpected street names with provided correct street names\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        st = m.group()\n",
    "        if st not in expected:\n",
    "            #print \"st not in expected\", st\n",
    "            if st in mapping:\n",
    "                #print \"st in mapping\"\n",
    "                name = re.sub(st, mapping[st], name)\n",
    "            else:\n",
    "                incomplete_mapping.add(st)\n",
    "    return name\n",
    "\n",
    "\n",
    "#### reshape the tags into an appropriate schema for mongo db repo\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        # YOUR CODE HERE\n",
    "        if element.tag == \"node\":\n",
    "            node['type'] = 'node'\n",
    "        elif element.tag == \"way\":\n",
    "            node['type'] = 'way'\n",
    "\n",
    "        atts = element.attrib\n",
    "        address = {}\n",
    "        pos = []\n",
    "        created = {}\n",
    "        node_refs = []\n",
    "        node['address'] = address\n",
    "        node['pos'] = pos\n",
    "        node['created'] = created\n",
    "        node['node_refs'] = node_refs\n",
    "        ### parent level attributes\n",
    "        for k,v in atts.iteritems():\n",
    "            if k == 'id':\n",
    "                node[k] = v\n",
    "            elif k == 'visible':\n",
    "                node[k] = v\n",
    "            elif k == 'amenity':\n",
    "                node[k] = v\n",
    "            elif k == 'name':\n",
    "                node[k] = v\n",
    "            elif k == 'phone':\n",
    "                node[k] = v\n",
    "            elif k == 'version':\n",
    "                created[k] = v\n",
    "            elif k == 'changeset':\n",
    "                created[k] = v\n",
    "            elif k == 'timestamp':\n",
    "                created[k] = v\n",
    "            elif k == 'user':\n",
    "                created[k] = v\n",
    "            elif k == 'uid':\n",
    "                created[k] = v\n",
    "            elif k == 'lon':\n",
    "                pos.append(float(v))\n",
    "            elif k == 'lat':\n",
    "                pos.append(float(v))\n",
    "                \n",
    "        #### child nodes\n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                node_refs.append(child.attrib['ref'])\n",
    "            elif child.tag == 'tag':\n",
    "                ktag = child.attrib['k']\n",
    "                vtag = child.attrib['v']\n",
    "                if not problemchars.match(vtag):\n",
    "                    if ktag == \"addr:city\":\n",
    "                        address['city'] = vtag\n",
    "                    elif ktag == \"addr:housenumber\":\n",
    "                        address['housenumber'] = vtag\n",
    "                    elif ktag == \"addr:postcode\":\n",
    "                        address['postcode'] = vtag\n",
    "                    elif ktag == \"addr:street\":\n",
    "                        address['street'] = vtag\n",
    "                    elif ktag == 'amenity':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'cuisine':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'name':\n",
    "                        node[ktag] = vtag\n",
    "                    elif ktag == 'phone':\n",
    "                        node[ktag] = vtag\n",
    "                        \n",
    "        if len(address) == 0:\n",
    "            del node['address']\n",
    "        if len(node_refs) == 0:\n",
    "            del node['node_refs']\n",
    "        if len(pos) == 0:\n",
    "            del node['pos']        \n",
    "        #print \"returning node: \", node\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#### main operator function that iterates through the xml\n",
    "### and gathers all info into multiple structures\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    users = set()\n",
    "    tags = {}\n",
    "    street_types = defaultdict(set)\n",
    "    data = []\n",
    "    context = ET.iterparse(filename, events=('start', 'end'))\n",
    "    context = iter(context)\n",
    "    file_out = \"{0}.json\".format(filename)\n",
    "    fo = codecs.open(file_out, \"w\")\n",
    "    for event, element in context:\n",
    "        if event == 'start':\n",
    "            if element.tag in tags:\n",
    "                tags[element.tag] += 1\n",
    "            else:\n",
    "                tags[element.tag] = 1\n",
    "            if element.tag == \"node\" or element.tag == \"way\":\n",
    "                for tag in element.iter(\"tag\"):\n",
    "                    if is_street_name(tag):\n",
    "                        audit_street_type(street_types, tag.attrib['v'])    \n",
    "    \n",
    "        keys = key_type(element, keys)\n",
    "        if 'user' in element.attrib:\n",
    "            users.add(element.attrib['user'])\n",
    "        \n",
    "    \n",
    "        el = shape_element(element)\n",
    "        if el:\n",
    "            data.append(el)\n",
    "            fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "\n",
    "    return tags, keys, users, street_types, data, file_out\n",
    "\n",
    "\n",
    "#### insert into db one record at a time\n",
    "\n",
    "def insert_mongo(data):\n",
    "    client = MongoClient()\n",
    "    dallasdb = client['udacity']\n",
    "    dallasarea = dallasdb['dallas']\n",
    "    for record in data:\n",
    "        if 'address' in record:\n",
    "            address = record['address']\n",
    "            street = address['street']\n",
    "            better_street = update_name(street, mapping)\n",
    "            address['street'] = better_street\n",
    "        nodeid = dallasarea.insert_one(record).inserted_id\n",
    "        print \"nodeid: \", nodeid, \" inserted\"\n",
    "    total_records = dallasarea.find().count()\n",
    "    print \"total records: \", total_records\n",
    "\n",
    "    \n",
    "###### main run function that brings it al together    \n",
    "def run():\n",
    "    filename = 'dallas_texas.osm'\n",
    "    tags, keys, users, street_types, data, file_out = process_map(filename)\n",
    "    #pprint.pprint(tags)\n",
    "    #pprint.pprint(keys)\n",
    "    print len(users)\n",
    "    print len(street_types)\n",
    "    #for st, ways in street_types.iteritems():\n",
    "    #    for name in ways:\n",
    "    #        better_name = update_name(name, mapping)\n",
    "            #print \"name: \", name, \" in st: \", st, \" corrected to: \", better_name\n",
    "    print \"incomplete mappings: \", len(incomplete_mapping)        \n",
    "    print len(data), \" records in json\"      \n",
    "    print \"db json @ \", file_out\n",
    "    #############################################\n",
    "    ##### THIS CAN TAKE VERY LONG ###############\n",
    "    ##### IT IS ADVISED TO USE mongoimport INSTEAD###\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # mongoimport --db udacity --collection dallas --file dallas_texas.osm.json  --drop\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ##############################################\n",
    "    #insert_mongo(data)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Lets check some data and clean up some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total records:  5558972\n",
      "data size:  1293651238.0\n",
      "first record:  {u'id': u'26450261', u'_id': ObjectId('56f1d4af222cc489da99b3f0'), u'type': u'node', u'pos': [-97.0027785, 32.9901295], u'created': {u'changeset': u'641383', u'version': u'4', u'user': u'brianboru', u'timestamp': u'2008-10-31T13:10:04Z', u'uid': u'9065'}}\n",
      "Top 5 Users\n",
      "User  5 {u'count': 2254674, u'_id': u'woodpeck_fixbot'}\n",
      "User  4 {u'count': 198416, u'_id': u'fmmute'}\n",
      "User  3 {u'count': 176820, u'_id': u'TexasNHD'}\n",
      "User  2 {u'count': 123490, u'_id': u'25or6to4'}\n",
      "User  1 {u'count': 121506, u'_id': u'Chris Lawrence'}\n",
      "Top 5 Zip Codes\n",
      "Zip Code  5 {u'count': 1211, u'_id': u'75104'}\n",
      "Zip Code  4 {u'count': 629, u'_id': u'75093'}\n",
      "Zip Code  3 {u'count': 343, u'_id': u'75070'}\n",
      "Zip Code  2 {u'count': 227, u'_id': u'75051'}\n",
      "Zip Code  1 {u'count': 181, u'_id': u'75069'}\n",
      "address records:  119075\n",
      "record :  1  :  {u'created': {u'changeset': u'15830886', u'version': u'3', u'user': u'starnix', u'timestamp': u'2013-04-22T22:52:44Z', u'uid': u'1381774'}, u'pos': [-96.747386, 32.4482], u'address': {u'street': u'Blue Ribbon Road', u'housenumber': u'329', u'postcode': u'75165'}, u'_id': ObjectId('56f1d4ef222cc489daa8530d'), u'type': u'node', u'id': u'82106539'}\n",
      "address.street:  Blue Ribbon Road\n",
      " \n",
      "record :  2  :  {u'created': {u'changeset': u'15830886', u'version': u'3', u'user': u'starnix', u'timestamp': u'2013-04-22T22:52:44Z', u'uid': u'1381774'}, u'pos': [-96.747386, 32.4482], u'address': {u'street': u'Blue Ribbon Road', u'housenumber': u'329', u'postcode': u'75165'}, u'_id': ObjectId('56f1d4ef222cc489daa8530e'), u'type': u'node', u'id': u'82106539'}\n",
      "address.street:  Blue Ribbon Road\n",
      " \n",
      "record :  3  :  {u'amenity': u'place_of_worship', u'name': u'Ash Creek Baptist Church', u'created': {u'changeset': u'24202681', u'version': u'3', u'user': u'wacomac', u'timestamp': u'2014-07-17T14:37:32Z', u'uid': u'2192676'}, u'pos': [-97.546412, 32.8879041], u'address': {u'city': u'Azle', u'street': u'South Stewart Street', u'housenumber': u'300', u'postcode': u'76020'}, u'_id': ObjectId('56f1d559222cc489dac28b70'), u'type': u'node', u'id': u'356699068'}\n",
      "address.street:  South Stewart Street\n",
      " \n",
      "record :  4  :  {u'amenity': u'place_of_worship', u'name': u'Ash Creek Baptist Church', u'created': {u'changeset': u'24202681', u'version': u'3', u'user': u'wacomac', u'timestamp': u'2014-07-17T14:37:32Z', u'uid': u'2192676'}, u'pos': [-97.546412, 32.8879041], u'address': {u'city': u'Azle', u'street': u'South Stewart Street', u'housenumber': u'300', u'postcode': u'76020'}, u'_id': ObjectId('56f1d559222cc489dac28b87'), u'type': u'node', u'id': u'356699068'}\n",
      "address.street:  South Stewart Street\n",
      " \n",
      "record :  5  :  {u'amenity': u'school', u'name': u'Crockett Middle School', u'created': {u'changeset': u'20001731', u'version': u'2', u'user': u'harryhorn', u'timestamp': u'2014-01-14T21:50:27Z', u'uid': u'1883497'}, u'pos': [-96.9780023, 32.8351818], u'address': {u'city': u'Irving', u'street': u'Hancock Street', u'housenumber': u'2431', u'postcode': u'75061'}, u'_id': ObjectId('56f1d559222cc489dac28d15'), u'type': u'node', u'id': u'356703423'}\n",
      "address.street:  Hancock Street\n",
      " \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "now that data is into mongo db, it is time to \n",
    "explore some of it and clean it further if necessary\n",
    "start with some basic statistics and run some \n",
    "aggregations. then try to clean up more street names\n",
    "'''\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "\n",
    "#### global with incorrect street types as regular expressions\n",
    "### this is a little different than lesson 6 problem set\n",
    "\n",
    "mapping = { \"\\bSt\": \"Street\",\n",
    "            \"\\bSt\\.\": \"Street\",\n",
    "            \"\\bRd\\.\": \"Road\",\n",
    "            \"\\bRd\": \"Road\",\n",
    "            \"\\bN\\.\": \"North\",\n",
    "            \"\\bAve\": \"Avenue\",\n",
    "            \"\\bTr\" : \"Trail\",\n",
    "            \"\\bTr\\.\": \"Trail\",\n",
    "            \"\\bTrl\": \"Trail\",\n",
    "            \"\\bS\\.\" : \"South\",\n",
    "            \"\\bW\\.\" : \"West\",\n",
    "            \"\\bW\" : \"West\",\n",
    "            \"\\bS\" : \"South\",\n",
    "            \"\\bW\" : \"West\",\n",
    "            \"\\bPkwy\" : \"Parkway\",\n",
    "            \"\\bpkwy\" : \"Parkway\",\n",
    "            \"\\bHwy\" : \"Highway\",\n",
    "            \"\\bE\" : \"East\",\n",
    "            \"\\bE\\.\" : \"East\",\n",
    "            \"\\bBlvd\" : \"Boulevard\",\n",
    "            \"\\bBlvd\\.\" : \"Boulevard\"\n",
    "            }\n",
    "\n",
    "#### connect to local mongodb instance and \n",
    "#### returns a db\n",
    "\n",
    "def connect():\n",
    "    client = MongoClient()\n",
    "    return client['udacity']\n",
    "\n",
    "\n",
    "#### do some simple stats and print out the results\n",
    "def simple_counts(db):\n",
    "    dallas = db['dallas']\n",
    "    records = dallas.count()\n",
    "    print \"total records: \", records\n",
    "    collstats = db.command(\"collstats\", \"dallas\")\n",
    "    print \"data size: \", collstats['size']\n",
    "    first_record = dallas.find()[0]\n",
    "    print \"first record: \", first_record\n",
    "    users = dallas.aggregate([\\\n",
    "        {\"$match\": {\"created.user\": {\"$exists\": 1}}},\\\n",
    "        {\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\":1}}},\\\n",
    "        {\"$sort\": {\"count\": -1}}\\\n",
    "                            ])\n",
    "    print \"Top 5 Users\"\n",
    "    i = 0\n",
    "    for u in users:\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print \"User \", 5-i, u\n",
    "        i += 1\n",
    "    \n",
    "    zipcodes = dallas.aggregate([\\\n",
    "        {\"$match\": {\"address.postcode\": {\"$exists\": 1}}},\\\n",
    "        {\"$group\": {\"_id\": \"$address.postcode\", \"count\": {\"$sum\": 1}}},\\\n",
    "        {\"$sort\": {\"count\": -1}}\\\n",
    "                                ])\n",
    "    print \"Top 5 Zip Codes\"\n",
    "    i = 0\n",
    "    for z in zipcodes:\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print \"Zip Code \", 5-i, z\n",
    "        i += 1\n",
    "\n",
    "### run some other finds and try to clean up more data\n",
    "\n",
    "def clean_street_names(db):\n",
    "    dallas = db['dallas']\n",
    "    address_records = dallas.find({\"address.street\": {\"$exists\": 1}})\n",
    "    print \"address records: \", address_records.count()\n",
    "    for i in range(0, 5):\n",
    "        record = address_records[i]\n",
    "        print \"record : \", i+1, \" : \", record\n",
    "        address_street = record['address']['street']\n",
    "        print \"address.street: \", address_street\n",
    "        for k, v in mapping.iteritems():\n",
    "            updated_street_name = re.sub(k, mapping[k], address_street, re.IGNORECASE)\n",
    "            #print \"Old Street Name: \", address_street, \"| New Street: \", updated_street_name\n",
    "            if not address_street == updated_street_name:\n",
    "                dallas.update({\"address.street\": address_street}, {\"$set\": {\"address.street\": updated_street_name}})\n",
    "                print \"updated street\", address_street, \" with new name \", updated_street_name\n",
    "        print \" \"\n",
    "    \n",
    "    \n",
    "#### main controller that brings all together\n",
    "def run():\n",
    "    db = connect()\n",
    "    simple_counts(db)\n",
    "    clean_street_names(db)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
